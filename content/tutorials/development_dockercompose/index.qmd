---
title: "Development/Docker: Compose"
format:
  html:
    toc: true
    html-math-method: katex
    code-fold: true
knitr:
  opts_chunk:
    echo: true
---


In this tutorial, I demonstrate how to set up and deploy a **custom docker container** with [**docker-compose**](https://docs.docker.com/compose).
This is intended to be a rather general test case, serving for later configuration of more specific container solutions.
I follow other tutorials available online, and try to capture their essence for an INBO-context.
Hence, this is just an assembly of other tutorials, with references - no original ideas to be found below.


Originally, this covers the steps to be executed on an (arch) linux computer or within a WSL.
On Windows, installation is different, yet there should be a linux-like terminal in the `docker desktop` app which would allow you to run the same commands.

I will later attempt to reproduce the steps on windows.



__References:__

- <https://jsta.github.io/r-docker-tutorial/02-Launching-Docker.html>
-   <https://medium.com/@geeekfa/docker-compose-setup-for-a-python-flask-api-with-nginx-reverse-proxy-b9be09d9db9b>
- <https://testdriven.io/blog/dockerizing-flask-with-postgres-gunicorn-and-nginx>


# Installation

The installation procedure [is documented here](https://docs.docker.com/compose/install).

Docker compose comes with the *Docker Desktop* app.
That app is probably trivial and hardly worth a tutorial.
Alternatively, you can install it as a terminal tool.


```{sh}
sudo apt update && sudo apt install docker docker-compose docker-buildx # debian-based
# sudo pacman -Sy docker docker-compose docker-buildx # arch linux
```


For users to be able to use docker, they must be in the "docker" group.
(Insert your username at `<your-username>`.)

```{sh}
sudo usermod -a -G docker <your-username>
```

For this change to take effect, log off en in again and restart of the docker service (see below).


Containers are managed by a system task ("service") which needs to be started.
Your system can start and stop that service automatically, by using `systemctl enable <...>`.  
However, due to [diverse](https://docs.docker.com/engine/security) [security](https://github.com/moby/moby/issues/9976) [pitfalls](https://snyk.io/blog/top-ten-most-popular-docker-images-each-contain-at-least-30-vulnerabilities), it is good practice to not keep it activated permanently on your system.


On a `systemd` system, you can start and stop docker on demand via the following commands (those will ask you for `sudo` authentification if necessary).

```{sh}
systemctl start docker

systemctl status docker # check status

systemctl stop docker.socket
systemctl stop docker.service
```


You can check the docker installation by confirming the version at which the service is running.

```{sh}
docker --version
```


# Existing Containers: `run`

## rationale

Docker is about working in containers, if you like that.
You can think of this as living in a ["tiny home", or "mobile home"](https://parametric-architecture.com/tiny-house-movement). 
Let's call it a fancy caravan.

If you do not have the cash to build your own home, you can of course use someone elses'.


## example

For example[^1], there are docker images with [rstudio server](https://posit.co/download/rstudio-server) pre-installed: 

- <https://hub.docker.com/r/rocker/rstudio>

[^1]: I mostly follow [this tutorial](https://jsta.github.io/r-docker-tutorial/02-Launching-Docker.html).


Execute the following script.
If it does not find the resources locally, docker will download and extract the image from dockerhub[^2].

[^2]: Just like "github" is a server service to store git repositories, guess what: "docker hub" is a service to store docker containers.

```{sh}
docker run --rm -p 8787:8787 -e PASSWORD=YOURNEWPASSWORD rocker/rstudio
```

- The `--rm` flag makes the docker image non-permanent, i.e. disk space will be freed after you close the container.
- The port specified at `-p` is the one you use to access this local container server. You have to specify it explicitly, otherwise the host system will not let your pass (`:gandalf-meme:`).
- The `-e` flag allows you to specify a password, but if you do not specify one, the container will provide a random password upon startup (read the terminal output).


You are now running (`run`) a `rocker/rstudio` server instance on your `localhost`, i.e. your computer.
You can access it via a browser, going to <localhost:8787>, with the username `rstudio` and your chosen password.


You can shut down the container with the keyboard shortcut `[ctrl]+[C]` (probably `[ctrl]+[Z]` on windows).


## file access

The downside of this is that your container is isolated (well... at least to a certain degree).

To store files locally, without storing the bloated container, you will have to map a virtual path on the container to a local drive on your computer.
(Linux people will be familiar with the concept of "mounting" and "linking" storage locations.)

Docker run brings the `-v` flag for this.
Suppose you have an R project you would like to work on, stored, for example, in this path:

- `/data/git/coding-club`

Then you can link this to your containers' home folder via the following command.

```{sh}
docker run --rm -p 8787:8787 -v /data/git/coding-club:/home/rstudio/coding-club rocker/rstudio
```

Again, navigate to <localhost:8787>, *et voilà*, you can access your project and store files back in your regular folders.


## limitation

This is a simple and quick way to run R and RStudio in a container.

However, there are limitations:

::: {.callout-warning}
- You have to live with the R packages provided in the container, or otherwise install them each time you access it...
- ... unless you make you container permanent by omitting the `--rm` option. Note that this will cost considerable disk space, will not transfer to other computers (the original purpose of docker), and demands occasional updates (next point).
- It is good practice to keep software up to date. Occasionally re-install your docker image and R packages to get the latest versions.
- You should make sure that the containers are configured correctly and securely. This is especially important with server components which expose your machine to the internet.
- There is a performance penalty from using containers: in inaccurate laymans' terms, they emulate (parts of a) "computer" inside your computer. 

:::


On the performance issue: I attempted this on my local laptop with matrix multiplication.

```{r}
# https://cran.r-project.org/web/packages/rbenchmark/rbenchmark.pdf
# install.packages("rbenchmark")

test <- function(){
  # test from https://prdm0.github.io/ropenblas/#installation
  m <- 1e4; n <- 1e3; k <- 3e2
  X <- matrix(rnorm(m*k), nrow=m); Y <- matrix(rnorm(n*k), ncol=n)
  X %*% Y
}

benchmark(test())
```

In the terminal:

```
    test replications elapsed relative user.self sys.self user.child sys.child
1 test()          100  22.391        1    83.961   65.291          0         0
```

In the container:

```
    test replications elapsed relative user.self sys.self user.child sys.child
1 test()          100  26.076        1   102.494   153.89          0         0
```

Now, the *good news* is that the difference is not by orders of magnitude, which indicates that docker seems to integrate the `blas` variant I installed on my computer (`blas-openblas`).

The *bad news* is that these are a little less than `-20%` performance, which is considerable.


This is just a single snapshot on a laptop. 
Feel free to systematically and scientifically repeat the tests on your own machine.


# Custom Containers: `build`

## rationale

One advantage of a docker container is its mobility: you can "bring it with you" to other workstations, use cloud computing, mostly without having to worry about installation of the components.
This especially pays off in complicated server setups and distributed computing.
The container is standardized; you could share it with colleagues to make sure versions are compatible.


However, as mentioned above, you will require personalization.
As a use case, imagine you would like to have an RStudio server which comes with relevant inbo packages pre-installed (e.g. [`inbodb`](https://inbo.github.io/inbodb), [`watina`](https://inbo.github.io/watina)).

I will return to this use case below.
To explore the general workings of `docker build`, let's first turn to more web-directed tasks.


## init: a `flask`

[Python `flask`](https://en.wikipedia.org/wiki/Flask_(web_framework)) is a library which allows you to execute python scripts upon web access by users.
For example, you can use flask to gather information a user provides in an html form, then process and store it wherever you like.


I will follow the following examples and tutorials to spin up a flask container, but provide modifications and comments on the steps.

- <https://docs.docker.com/build/concepts/dockerfile>
- <https://medium.com/@geeekfa/dockerizing-a-python-flask-app-a-step-by-step-guide-to-containerizing-your-web-application-d0f123159ba2>



> **It all starts with a [dockerfile](https://www.geeksforgeeks.org/what-is-dockerfile).**[^3]

[^3]: <https://docs.docker.com/build/concepts/dockerfile>


As you will see, the docker file will give you all the design choices to create your own container.
I think of the docker file as a script which provides all the instructions to set up your container, starting with `FROM` (i.e. which prior container you build upon) to `RUN`ning commands.


A list of the official python containers is [available here](https://hub.docker.com/_/python).
Note that you build every container upon the skeleton of an operating system: I chose [alpine linux](https://en.wikipedia.org/wiki/Alpine_Linux).


The dockerfile resides in your working folder (yet it also defines a [`WORKDIR`](https://stackoverflow.com/a/51066379) from within which later commands are executed).

- Navigate to a folder in which you intend to store your container(s), e.g. `cd /data/docker`.
- Create a file called `Dockerfile`: `touch Dockerfile`.
- Edit the file in your favorite text editor (`vim Dockerfile`): paste and modify the content below.

```{dsl}
# Use the official Python image (alpine linux, python 3)
FROM python:3-alpine

# install app dependencies
RUN apk update && apk add --no-cache python3 py3-pip
RUN pip install flask

# install app
COPY hello.py /

# final configuration
ENV FLASK_APP=hello
EXPOSE 8000
CMD ["flask", "run", "--host", "0.0.0.0", "--port", "8000"]
```


Note that the following `hello.py` file needs to be present in your working directory:

```{python}
from flask import Flask
app = Flask(__name__)

@app.route("/")
def hello():
    return "Hello, INBO!"
```


With the `Dockerfile` and `hello.py` in place, you can build the container [^4].

```{sh}
sudo docker build -t my-flask .
```

[^4]: If you did not install the `docker-buildx` package, you will get a legacy warning.


List your available containers ("images") via the `docker images` command!

You should now see a `python` image, which is the base alpine image we built upon.
There is also a `my-flask`. 
Try it!

```{sh}
docker run my-flask
```

The terminal should give you an IP and port; because the flask runs in a container, `localhost:8000` will not work out-of-the-box.
Instead, in my case, it was `http://172.17.0.2:8000`.


:::{.callout-note}
So far, so good. 
We have used an existing image and added `flask` on top of it.
This works via writing a `Dockerfile` and building an image.
:::


## Multiple Images: `compose` versus `build`

The above works fine for most cases.
However, if you want to assemble multiple images, or build on base images from multiple sources, you need a level up.

In that case `docker compose` is [the way to go](https://docs.docker.com/compose/gettingstarted).



# Use Case: RStudio with Packages

## rationale

We should be able to apply the above to modify the `rocker/rstudio` server image for our purpose.


## dockerfile

This use case is, in fact, well documented:

- <https://rocker-project.org/use/extending.html>
- <https://rocker-project.org/images/versioned/rstudio.html>
- <https://davetang.org/muse/2021/04/24/running-rstudio-server-with-docker>


Note the syntax in `FROM`: it is `rocker/<image>:<version>`.

```{dsl}
# Use the rocker rstudio image
FROM rocker/rstudio:latest

# update the system packages
RUN apt update \
    && apt upgrade --yes

# git2rdata requires git
RUN apt install git libgit2-dev --yes

# update pre-installed R packages
# RUN Rscript -e 'update.packages(ask=FALSE)'

# install package via Rscript
# (a) via r-universe
# RUN Rscript -e 'install.packages("watina", repos = c(inbo = "https://inbo.r-universe.dev", CRAN = "https://cloud.r-project.org"))'
RUN Rscript -e 'install.packages("git2rdata")'

# (b) from github
RUN R -q -e 'install.packages("remotes")'
RUN R -q -e 'remotes::install_github("inbo/INBOmd", dependencies = TRUE)'
```

It takes some puzzle work to get the dependencies right, e.g. with the `libgit2` dependency above (try commenting out that line).
However, there is hope: (i) the error output is quite instructive (at least for linux persons), (ii) building is incremental, so you can add successively.
Remember which system powers your container (Debian/Ubuntu), find help online, and document your progress.


Test the image:

```{sh}
docker build -t test-rstudio .
```


Run it:

```{sh}
docker run --rm -p 8787:8787 -e PASSWORD=YOURNEWPASSWORD test-rstudio
```


It is useful to put modifications in scripts copied and executed upon installation:
https://stackoverflow.com/q/69167940
e.g. https://rocker-project.org/use/extending.html#install2.r

This makes them available for version control.


# useful commands

We have briefly seen `docker --version`, `docker build`, `docker run`, and there are certainly more settings and tweaks on these commands to learn about.

There are other docker commands which might help you out of a misery.

- `docker images` will list your images in convenient table format; the `-q` flag returns only IDs.
- `docker inspect <image-name or image-id>` brings up all the configuration details about a specific image; you can, for example, find out its docker version and network ip.
- `docker rmi <image-name or image-id>` will remove an image; `docker rmi $(docker images -q)` will remove **all** your images. Of course, you get to keep the dockerfiles.
- `docker ps` ("print status") will list all running containers; `docker stop $(docker ps -a -q)` will stop them **all**.

There are a gazillion more to choose and use, the [docker docs](https://docs.docker.com/reference/cli/docker) are your go-to source.


# Podman

## purpose

Whales don't really carry "containers", and "images" are better hung on a wall. 
Don't fall for the docker marketing!


There are alternatives which mitigate some of the docker limitations and disadvantages.

The most prominent one (the only one *I* looked at, sorry) might be `podman`.
A container is a "pod", they run on a "machine", and this tool helps you manage them.
The major advantage of podman is that it can be configured to run **"rootless"**, i.e. without administrator rights [^5].

[^5]: Daniel J. Walsh (2019): "How does rootless Podman work?" <https://opensource.com/article/19/2/how-does-rootless-podman-work>


Podman is [well documented](https://podman.io/docs/installation).
Another reliable source as so often is the [arch linux wiki on podman](https://wiki.archlinux.org/title/Podman), no matter which linux you are on.
On windows, people have succeeded in running podman through a WSL.


## setup

I follow the `podman` installation instructions for arch linux, to set up a **rootless container environment**.

Installation:

```{sh}
pacman -Sy podman podman-compose podman-docker passt
```

The last one, `passt` (providing `pasta`, yum!), is required for rootless network access.  


Normally, podman will run *only if you are root*. 
This has to be changed, to get *rootless* ([see also](https://man.archlinux.org/man/podman.1#Rootless_mode))
The first step is to confirm a required kernel module: check that `unpriviledged_users_clone` is set to one.

```{sh}
sysctl kernel.unprivileged_userns_clone
```

Then, configure "subordinate user IDs". 
There are detail differences in each linux distro; with some luck, your username is already present in these lists:

```{sh}
cat /etc/subuid
cat /etc/subgid
```

If not, you can be admitted to the club of subordinates with the command:
```{sh}
usermod --add-subuids 100000-165535 --add-subgids 100000-165535 <username>
podman system migrate
```


We note some useful commands on the way: `podman system ...` and `podman info`.
You might immediately check "native rootless overlays" (has something to do with mounting filesystems in the container):

```{sh}
podman info | grep -i overlay
```


Then, networking: pods might need to communicate to each other and to the world.
And, of course, container storage: make sure you know where your containers are stored.
These and more settings are in `/etc/containers/containers.conf` and `/etc/containers/storage.conf`; make sure to scan and edit them to your liking.


## usage

You can use images from `docker.io` with podman.
For example:

```{sh}
podman search docker.io/alpine
podman pull docker.io/alpine # download a machine
podman run -it docker.io/alpine # will connect to the container
exit
```


## podman rocker

From here, **podman is a full drop-in replacement for docker**; just that you are not forced to grant host system root privileges to containers.

And you can use any docker image; `rocker/rstudio` [is available](https://rocker-project.org/use/rootless-podman.html) (don't forget to specify the port).

```{sh}
podman run --rm -p 8787:8787 -e PASSWORD=YOURNEWPASSWORD -v /data/git/coding-club:/root/coding-club docker.io/rocker/rstudio
```

With one exception: the user to login to `rstudio` is not `rstudio`, but `root`, and you have root rights on the container. 
You had those before anyways, but now they are confined to within the pod.



:::{.callout-note}
To summarize:

- **Docker's Dockerfiles like the one above will build as with docker.**
- You can even stick to the `docker` commands thanks to the `podman-docker` package.
- There is podman desktop, if you like clicking.
- Podman is everything docker is, just better.

:::

Kudos to the podman devs!


Your head might twisting in a swirl of containers by now, and will leave it here.
Thank you for reading!


# TODO 

- [✓] bugfix the last RStudio variant
- [✓] list useful docker commands
- [✓] Podman is available. <https://rocker-project.org/use/rootless-podman.html>
- [ ] port to windows: (1) docker
- [ ] port to windows: (2) podman
- [ ] insert screenshots
